This file contains a brief description of the project and the commands for compiling and running. 
For detailed description of the task, see Task.pdf.
For detailed report on the solution, See report.pdf
The dataset for this project is taken from: http://people.cs.kuleuven.be/~toon.vancraenendonck/bdap_files/

****************** BRIEF DESCRIPTION ******************
*******************************************************

This project contains two subtasks to analyze the GPS tracks data of taxis in San Francisco. First, the distribution of trip lengths in a month is computed locally in a Spark environment and its efficiency is compared with a non-Spark local implementation. The objective is to analyze the performance of the single-node Spark implementation for this small dataset. I showed that the non-spark implementation is somewhat faster than the single node spark execution as there is no overhead to organize the data for shuffle in the former method. The second task is to identify airport trips and compute an estimate of the total revenue obtained from them. For this task, I designed various Map and Reduce functions (in Java) to exploit MapReduce with data whose size is greater than 4GB and to implement an efficient and scalable approach to solve the task.


working directory: src

*********************** COMPILE ***********************
*******************************************************

mvn clean package


************************* RUN *************************
*********** TRIP_LENGTH_DISTRIBUTION (SPARK)***********

$SPARK_INSTALL/bin/spark-submit --class Assignment3.LengthDistribution --master local[*] Excercise1_spark/target/Excercise1.jar <PATH_TO_INPUT_FILE> <PATH_TO_OUTPUT_FILE> <NUMBER_OF_BINS> <FIND_OUTLIERS?:true|false>

ex:
$SPARK_INSTALL/bin/spark-submit --class Assignment3.LengthDistribution --master local[*] Excercise1_spark/target/Excercise1.jar /data/2010_03.trips Excercise1_spark/output 10 true


************************* RUN *************************
**************** AIRPORT_RIDE_REVENUE *****************

hadoop jar Excercise2/target/Excercise2.jar Assignment3.AirportRideRevenueMain <PATH_TO_INPUT_FILE> <PATH_TO_OUTPUT_FILE> <NO_OF_REDUCERS_STAGE_1> <NO_OF_REDUCERS_STAGE_2> <CONSIDER_OVERLAPPING_SEGMENTS?:true|false> <RECONSTRUCT_AIRPORT_TRIPS_ONLY?:true|false>

ex: 
hadoop jar Excercise2/target/Excercise2.jar Assignment3.AirportRideRevenueMain /data/all.segments /user/r0605648/output 9 1 true true







***** TRIP_LENGTH_DISTRIBUTION (LOCAL NON-SPARK) ******

********** COMPILE (Requires Scala 2.12.1) ************

$SCALA_HOME/bin/scalac -d Excercise1_non_spark/ Excercise1_non_spark/LengthDistributionLocal.scala

************************* RUN *************************

$SCALA_HOME/bin/scala -classpath Excercise1_non_spark LengthDistributionLocal <PATH_TO_INPUT_FILE> <PATH_TO_OUTPUT_FILE> <NUMBER_OF_BINS> <FIND_OUTLIERS?:true|false>

ex:
$SCALA_HOME/bin/scala -classpath Excercise1_non_spark LengthDistributionLocal /data/2010_03.trips Excercise1_non_spark/output.txt 10 true






<<-----------------------PLOT------------------------>>

*********** TRIP_LENGTH_DISTRIBUTION (SPARK)***********

python plot.py <PATH_TO_OUTPUT_FILE> 'Length Distribution'

ex: python plot.py Excercise1_non_spark/output.txt 'Length Distribution'


**************** AIRPORT_RIDE_REVENUE *****************

python plot.py <PATH_TO_OUTPUT_FILE> 'Airport Revenue'

python plot.py Excercise2/output/Airport_Trips_Revenue-r-00000 'Airport Revenue'


<<--------------------------------------------------->>

